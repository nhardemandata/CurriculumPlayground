{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "abb15bdc-48f6-49c9-99c8-1de8639cfd87",
   "metadata": {},
   "source": [
    "# DSO105 Int Stats Page 4 and 5 revamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36060db1-fe6a-4bb1-8f46-6697ef265788",
   "metadata": {},
   "outputs": [],
   "source": [
    "## in R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7648aaa-4c99-4923-a40d-78c7dd3ce459",
   "metadata": {},
   "outputs": [],
   "source": [
    "## load libraries\n",
    "\n",
    "\n",
    "install.packages('rcompanion')\n",
    "install.packages('car')\n",
    "install.packages('readxl')\n",
    "\n",
    "library(tidyverse)\n",
    "library(IDPmisc)\n",
    "library(rcompanion)\n",
    "library(car)\n",
    "library(readxl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b07d89b-a487-4957-943c-250929231561",
   "metadata": {},
   "outputs": [],
   "source": [
    "## load data for one way between subjects Anova in R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc6fc41-454d-46ca-8d4b-3df3ea8ad7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc = read.csv('../../datasets/PlayData/BankChurners.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3827ff3f-f18a-420e-9ee1-8c7dd153725b",
   "metadata": {},
   "outputs": [],
   "source": [
    "head(cc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc747d4-a416-4fcd-9d27-59c48249337f",
   "metadata": {},
   "source": [
    "#### list out all column value counts to get an idea of your data and what to look for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0e167e-4b06-440d-9e2a-116f7f1461bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique(cc[c(\"Card_Category\")])\n",
    "## lets see if there is a difference in age among the 4 card categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b620a3d9-06ab-4592-a372-f6034a0ff1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## make sure your DV is continuous (age is already)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e924ad1-9c50-43eb-a004-d9aa35124c07",
   "metadata": {},
   "source": [
    "## One Way Between Subjects ANOVAs in R\n",
    "\n",
    "Now that you have a basic idea about what an ANOVA is, you will learn how to create ANOVAs in R, starting with the One Way ANOVA.\n",
    "\n",
    "## Load Libraries\n",
    "\n",
    "ANOVAs come as part of the base package in R, so the only libraries you will need to load in are dplyr because you'll need it for some data wrangling, rcompanion because you'll use it to check for the assumption of normality, and car if you need to run an ANOVA that will correct for a violation of homogeneity of variance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af0f0da-088a-4ed7-b59d-9e1bdb09e669",
   "metadata": {},
   "source": [
    "## Question Setup\n",
    "\n",
    "With this data, you will answer the question:\n",
    "\n",
    "*Is there a difference in age among the 4 card categories?*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72364be0-f1da-4ce3-858f-704594031c6a",
   "metadata": {},
   "source": [
    "**In order to answer this question, your x, or independent variable, will be the Card_Category, which has four levels: Blue, Silver, Gold, and Platinum. Your y, or dependent variable, will be the Customer_Age. As with all ANOVAs, the IV will be categorical, and the DV will be continuous.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f624a5c-8b88-44a5-9e25-ebb271916aa5",
   "metadata": {},
   "source": [
    "## Data Wrangling\n",
    "\n",
    "Depending on the data that you've been given, it may need some wrangling!\n",
    "\n",
    "## Filter the Data and Remove Missing Values\n",
    "\n",
    "In this case we do not need to filter any of our categorical variables, because we are using all four card levels. All that is left is to drop the missing data and make sure our DV (Customer_Age) is numeric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce54b5bb-39a8-4434-9d89-90b2d14c6329",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc1 = na.omit(cc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2df1d5f-9848-4682-b23d-2c8bc5615b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "head(cc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f52780b-dfea-4f08-ae16-f2262ab86ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "str(cc1)\n",
    "## Customer_Age is an integer so we are good to proceed!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca46892a-c7fd-4815-8f04-9f9213682bff",
   "metadata": {},
   "source": [
    "## Test Assumptions\n",
    "\n",
    "Before you go any further, it's important to test for assumptions. If the assumptions are not met for ANOVA, but you proceeded anyway, you run the risk of biasing your results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ec30dd-1840-4256-ad61-8bd34c6432f1",
   "metadata": {},
   "source": [
    "## Normality\n",
    "\n",
    "You only need to test for the normality of the dependent variable, since the IV is categorical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b6f966-2523-4aaf-8f73-eea65f076d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotNormalHistogram(cc1$Customer_Age)\n",
    "## This looks approx. normally distributed - alright!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e51804-ac1b-4b53-b904-19729387d8c1",
   "metadata": {},
   "source": [
    "## Homogeneity of Variance\n",
    "\n",
    "You can test for homogeneity of variance easily using either Bartlett's test or Fligner's Test. Bartlett's test is for when your data is normally distributed, and Fligner's test is for when your data is non-parametric. No matter which test you are using, you are looking for a non-significant test. The null hypothesis for both of these is that the data has equal variance, so you'd like to have a p value of > .05. You have already determined your data is normally distributed, so ordinarily you would just perform Bartlett's test, but just for learning purposes, you'll try both here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33cd921a-5e1b-49e5-9194-5fefd49198fa",
   "metadata": {},
   "source": [
    "### Bartlett's Test\n",
    "\n",
    "To do Bartlett's test, use the function bartlett.test(), with the argument of the y data separated by a tilde, followed by the x data. Then there's an argument data=, which is where you will specify the name of your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319484a8-fbf1-4010-a490-4e6be43778c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "bartlett.test(Customer_Age ~ Card_Category, data = cc1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938c6fb3-6e63-41ce-a71e-8d52b969b4c2",
   "metadata": {},
   "source": [
    "The p value associated with this test is < .05, which means that unfortunately, you have violated the assumption of homogeneity of variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362e1638-e834-4415-a8f9-f3473a10a884",
   "metadata": {},
   "outputs": [],
   "source": [
    "## this kind of makes sense, as cc customers of all ages have various levels of credit, \n",
    "## so there is more reason to believe that there is heterogeneity of variance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44dbb56-9ee3-481c-a4fa-857891030342",
   "metadata": {},
   "source": [
    "### Fligner's Test\n",
    "\n",
    "To perform Fligner's test, use the function fligner.test(), with the argument of the y data separated by a tilde, followed by the x data. Then there's an argument data=, which is where you will specify the name of your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2659c534-875d-4da0-97b5-17fb22e1f6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fligner.test(Customer_Age ~ Card_Category, data = cc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b72d8e-a208-4ba6-8f35-92dc5af8756a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## still shows violation of assumption of homogeneity of variance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f603ac-c79e-4f19-9e91-9fbaf3af9edb",
   "metadata": {},
   "source": [
    "## Correcting for Violations of Homogeneity of Variance\n",
    "\n",
    "There are two ways that you can correct for a violation of homogeneity of variance. The first is the BoxCox transformation of your data, and the second is running a slightly different type of ANOVA, one that was created specifically to handle this violation. That test is called the Welch One-Way Test, and you'll learn about this ANOVA option."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be74ef18-895c-4563-b585-74a864466b2c",
   "metadata": {},
   "source": [
    "## Sample Size\n",
    "\n",
    "An ANOVA requires a sample size of at least 20 per independent variable. In this case, you only have one independent variable, so as long as you have at least 20 cases, you are fine. Looking at the data, the n is 10127, so you are fine to proceed with this assumption!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474426ef-7e13-4412-81fd-49f1d948ee1a",
   "metadata": {},
   "source": [
    "## Independence\n",
    "\n",
    "There is no statistical test for the assumption of independence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "befeb433-6a2f-4da0-8212-4f7c999789ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Page 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df7d3619-9829-43d8-b70d-c2969eff0fe4",
   "metadata": {},
   "source": [
    "## Computing ANOVAs with Equal Variance (Met Homogeneity of Variance Assumption)\n",
    "\n",
    "In this case, your data did not meet this assumption, but for the purposes of learning, you'll be shown what to do if you had.\n",
    "\n",
    "Below is the code to run a one-way ANOVA in R. You can give your ANOVA a name; this one is named cc1ANOVA. Then you want to use the function aov(). The argument for this function is your y variable, which is continuous, followed by a tilde and then your x variable, which is categorical. Remember that the tilde reads as \"by,\" so you can think of this as analyzing age by card category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355509d6-1336-4d5f-96db-fb65cb33879e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc1ANOVA <- aov(cc1$Customer_Age ~ cc1$Card_Category)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f172d0af-5078-4f3d-b800-f397b7d317be",
   "metadata": {},
   "source": [
    "You need to utilize the summary() function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f854c507-693d-46cc-9f10-168c4db098c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(cc1ANOVA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09a7aa1-7bc9-4724-8cba-d7c3bebe28ac",
   "metadata": {},
   "source": [
    "The first row of the output has the Df, or degrees of freedom. The row for your category is calculated as # of Levels - 1, so that is always a good gut check. Next, you have rows for the Sum Sq and Mean Sq; these are just some of the calculations that went into getting your F value, which is the test statistic for an ANOVA. The real meat that you want to pay attention to is the F value itself and the associated p value next to it. Like anything else, if this value is less than .05, the test was significant. If you ever need a reminder of that, you can look at the star and Signif. codes down at the bottom - there's one star listed, so it is significant at .05."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06aac70-4d30-4334-bfdc-1689bb00732e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## the star and signif codes do not appear in R/Jup Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22258814-65a1-43c6-86e0-93a5921f5bee",
   "metadata": {},
   "source": [
    "## Computing ANOVAs with Unequal Variance (Violated Homogeneity of Variance Assumption)\n",
    "\n",
    "If you need to correct for violating the assumption of homogeneity of variance, you can run an ANOVA that was meant to correct for that violation, using a Welch's One-Way Test. To do this, you will actually create a linear model first, and then use the function Anova() on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ea0c0c-69e7-41f1-b072-d97cb8a91fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## this is the ANOVA we would like to run since we have heterogeneity of variance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca12e7a8-352b-43b2-9b78-ccbc57ef646d",
   "metadata": {},
   "source": [
    "First, create and name a linear model that uses the same set up as the ANOVA with equal variance. Then, call the Anova() function on that named model, include the argument of Type= and set it to \"II\" because this is a between subjects ANOVA, and then use the argument white.adjust=TRUE. This last part, setting white.adjust= to TRUE, is what makes this ANOVA appropriate when you have unequal variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc96403b-28d5-4527-8896-cbe2d63ba2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ANOVA <- lm(Customer_Age ~ Card_Category, data = cc1)\n",
    "Anova(ANOVA, Type=\"II\", white.adjust=TRUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73eb12ea-752b-4094-992a-5ae90c842dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "## need to run in R to see the star and signif codes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e0cdae-68b5-4fe8-82c1-561b4f8d3bdd",
   "metadata": {},
   "source": [
    "## Post Hocs\n",
    "\n",
    "Now the problem with an ANOVA is that you have multiple groups. When you found significance with a t-test, you were able to just look at the means and you knew where the significant differences lie. You knew what was higher, and what was lower. But with an ANOVA, you can't just look at the means right away, because the F and associated p value just let you know that there is a difference between at least set of the three categories. In your example, the mean prices could be different between the beauty and food and drink category, the beauty and photography category, the food and drink and photography category, or some combination of those three!\n",
    "\n",
    "That's where post hocs come in. They are specifically designed to test all the pairs between your data, which is why they are also often known as pairwise comparisons. This is done with t-tests. But the inherent problem with using multiple t-tests is that the more analyses you run, the more you increase your chances of Type I error. So you're more likely to find something significant when it really isn't. So, typically a post hoc will apply a correction, or adjustment, so that the t-tests become more stringent, and you are therefore correcting for doing multiple t-tests by applying stricter criteria. That way your Type I error doesn't run rampant!\n",
    "\n",
    "There are many different corrections you can apply. But the most common ones you'll hear about are Tukey, Bonferroni, Holm, and Scheffe. All named by after the people who came up with them, by the way. These three are in order of how much correction they apply, with Tukey applying the least correction and Scheffe applying the most. Unfortunately, R does not compute Tukey and Scheffe automatically, so you'll stick to exploring the difference between no correction at all, and a Bonferroni correction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fcec51b-8d4d-45e8-8e98-9d1018f25c1a",
   "metadata": {},
   "source": [
    "## Computing Post Hocs with No Adjustment\n",
    "\n",
    "Use the pairwise.t.test() function, with the arguments of the two variables you are crossing, and the argument p.adjust=. To show you why a correction is necessary, you will start out with a value of \"none\", which means that no correction is being made for Type I error. Here are the results:\n",
    "\n",
    "Here is the code for computing a post hoc in R:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243ca487-2e0d-491f-8b2b-087f8369ef01",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairwise.t.test(cc1$Customer_Age, cc1$Card_Category, p.adjust=\"none\")\n",
    "## no correction for Type 1 Error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dcc081c-336e-40c5-a3c3-6375e1835212",
   "metadata": {},
   "source": [
    "What is presented in the matrix above is the p values for each t-test between the pairs of the levels of your independent variable. Reading this, you can see that there was not a significant difference in age between Gold and Blue, Platinum and Blue, Gold and Platinum, Gold and Silver, and Silver and Platinum.  There is, however, a significant difference between the age of customers using Blue and Silver cards, at p = .048."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2d1c23-bd48-4b86-a246-daaec63024ec",
   "metadata": {},
   "source": [
    "## Computing Post Hocs with Bonferroni Adjustment\n",
    "\n",
    "You may be pretty pleased with finding a significant difference in age between card categories. But guess what? That difference may not really exist, because by running four t-tests, you may have increased your Type I error. So, better to typically stick with some form of correction, like Bonferroni. It is relatively \"mild,\" but gets the job done!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d94e6b1-a519-4eb2-afcf-f4831bae1a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairwise.t.test(cc1$Customer_Age, cc1$Card_Category, p.adjust=\"bonferroni\")\n",
    "## here we are correcting for Type 1 Error\n",
    "## taking into a count the several t-tests we are running"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a9be65-92ce-43a3-97a2-325590e6abe0",
   "metadata": {},
   "source": [
    "We see that our significant p-value is no longer significant.\n",
    "\n",
    "We also see that our non-significant p-values became even more non-significant.With Blue and Gold, going from 0.213 to 1.00, and with others.\n",
    "\n",
    "Since a p value can only be between 0 and 1, that's the end of line; as non-significant as something gets. This has just demonstrated why it's important to always, always, apply a correction to your post hocs!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57ff09b-11c5-447f-b575-b8aa4067c3be",
   "metadata": {},
   "source": [
    "## Computing Post Hocs When You've Violated the Assumption of Homogeneity of Variance\n",
    "\n",
    "There is an easy solution to computing post hocs when you have violated the assumption of homogeneity of variance. You'll use the same codes as above, but include the argument pool.sd = FALSE at the end. Like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59130e2-8715-4424-8542-9560f32fa932",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairwise.t.test(cc1$Customer_Age, cc1$Card_Category, p.adjust=\"bonferroni\", pool.sd = FALSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d4d47c-47d6-433a-913e-8c83c45d4491",
   "metadata": {},
   "source": [
    "This provides a very similar output, the only difference being that is was calculated with non-pooled standard deviations, as noted at the top."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47add39-01fa-4b40-a7c3-904dbff80a7f",
   "metadata": {},
   "source": [
    "As you can see, once you've correct for this assumption, your results are more accurate, and your pairwise comparisons are still not significant, but give a more accurate p-value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3ea785-af73-4d0a-86b5-86bef42f412e",
   "metadata": {},
   "source": [
    "## Determine Means and Draw Conclusions\n",
    "\n",
    "If you had found a significant difference after correction, you would want to then finish interpreting the results and draw some conclusions. To do that, you need to examine the means! Again, dplyr nicely comes to the rescue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19349ae5-0909-4ce7-847b-2e299de3eb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc1Means = cc1 %>% group_by(Card_Category) %>% summarize(Mean = mean(Customer_Age))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9ffa29-7b87-4933-9961-10386ade96bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc1Means"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f51bec45-a2f4-4e81-b903-9766e156ac49",
   "metadata": {},
   "source": [
    "Had you passed the corrected post-hoc with this data, you would have been able to look at the means and say that the Platinum card had a significantly higher average customer age than Gold or Silver cards. But, looking at these means, which are extremely close, it makes sense that this significant finding would \"wash out\" after Bonferroni correction. Is the difference between 45.5 years and 47.5 years really all that different?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102746f5-2123-49ff-be47-9f1b18fd68d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "libpaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a81421-599e-4f90-b708-7dbe8ef3ae8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "install.packages('libpaths')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0adaff0-076f-45ad-ba86-a631512352bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef8681c-688f-4187-bae0-eef8dc789603",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e46b2b-6a55-415d-a3ef-20a442dd7717",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f45f6b-c95b-4949-b894-12677965edff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08694d18-47ce-42a9-bbcb-9427b9aa594b",
   "metadata": {},
   "outputs": [],
   "source": [
    "findPkgAll <- function(pkg)\n",
    "  unlist(lapply(.libPaths(), function(lib)\n",
    "           find.package(pkg, lib, quiet=TRUE, verbose=FALSE)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f1c1e5-43b0-44bd-9360-19e5532960c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "findPkgAll(\"MASS\")\n",
    "findPkgAll(\"knitr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa096abb-ae1e-4821-be36-5d069f8b4c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "install.packages('tidyverse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8e2e49-ecac-46b7-9c2b-6f9aec8930dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "findPkgAll(\"tidyverse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574d099a-bb97-4119-9c7e-d2d516831d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "findPkgAll('readxl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909d4b32-9c3b-4d08-9176-3c0dac2f8804",
   "metadata": {},
   "outputs": [],
   "source": [
    "border = read_xlsx('C:/Users/nolan/OneDrive/Documents/GitHub/CurriculumPlayground/datasets/BorderCrossing.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d4ee11-fde1-4360-984e-588365459cbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43be2cbe-c8e2-41bf-b16a-c31da0d32f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "read_excel() read_xls() read_xlsx()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
