{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e90bf2b-2686-472b-be89-7fbe8a8b7cc1",
   "metadata": {},
   "source": [
    "# DSO 105 Intermediate Stats L3 - R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f69daae-61d0-4b35-8310-22242f21318b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## When you have 1 or more categorical varialbe you can either do: proportion testing or Chi-Square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "25c393a2-41e0-4790-b07a-61c80f30d8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Page 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4392a1ce-6d37-4d4e-892e-154d3ce31ae7",
   "metadata": {},
   "source": [
    "By the end of the lesson, you should be able to conduct the following in both Python and R:\n",
    "\n",
    "* One proportion tests\n",
    "\n",
    "* Two proportion tests\n",
    "\n",
    "* Independent Chi-Squares\n",
    "\n",
    "* Goodness of fit Chi-Squares\n",
    "\n",
    "* McNemar Chi-Squares\n",
    "\n",
    "In addition, you should also be able to:\n",
    "\n",
    "* Differentiate between the different types of categorical tests\n",
    "\n",
    "* Test assumptions and perform post hoc analysis for Chi-Squares in R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a448e505-73db-461f-9b19-55a848dfe18f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Installing package into 'C:/Users/nolan/OneDrive/Documents/R/win-library/4.1'\n",
      "(as 'lib' is unspecified)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "package 'gmodels' successfully unpacked and MD5 sums checked\n",
      "\n",
      "The downloaded binary packages are in\n",
      "\tC:\\Users\\nolan\\AppData\\Local\\Temp\\RtmpiEyzz1\\downloaded_packages\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Installing package into 'C:/Users/nolan/OneDrive/Documents/R/win-library/4.1'\n",
      "(as 'lib' is unspecified)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "package 'tidyverse' successfully unpacked and MD5 sums checked\n",
      "\n",
      "The downloaded binary packages are in\n",
      "\tC:\\Users\\nolan\\AppData\\Local\\Temp\\RtmpiEyzz1\\downloaded_packages\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "-- \u001b[1mAttaching packages\u001b[22m ------------------------------------------------------------------------------- tidyverse 1.3.1 --\n",
      "\n",
      "\u001b[32mv\u001b[39m \u001b[34mggplot2\u001b[39m 3.3.3     \u001b[32mv\u001b[39m \u001b[34mpurrr  \u001b[39m 0.3.4\n",
      "\u001b[32mv\u001b[39m \u001b[34mtibble \u001b[39m 3.1.2     \u001b[32mv\u001b[39m \u001b[34mdplyr  \u001b[39m 1.0.6\n",
      "\u001b[32mv\u001b[39m \u001b[34mtidyr  \u001b[39m 1.1.3     \u001b[32mv\u001b[39m \u001b[34mstringr\u001b[39m 1.4.0\n",
      "\u001b[32mv\u001b[39m \u001b[34mreadr  \u001b[39m 1.4.0     \u001b[32mv\u001b[39m \u001b[34mforcats\u001b[39m 0.5.1\n",
      "\n",
      "-- \u001b[1mConflicts\u001b[22m ---------------------------------------------------------------------------------- tidyverse_conflicts() --\n",
      "\u001b[31mx\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mfilter()\u001b[39m masks \u001b[34mstats\u001b[39m::filter()\n",
      "\u001b[31mx\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mlag()\u001b[39m    masks \u001b[34mstats\u001b[39m::lag()\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## load libraries\n",
    "\n",
    "install.packages('gmodels')\n",
    "install.packages('tidyverse')\n",
    "\n",
    "\n",
    "library(gmodels)\n",
    "library(tidyverse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94cdb969-c6cd-436c-9928-3809372cf7fd",
   "metadata": {},
   "source": [
    "## One Proportion Testing\n",
    "\n",
    "One proportion testing is used when you want to see whether the proportion of two things are similar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9ee967-4485-43cb-bdcb-cc750fbed43c",
   "metadata": {},
   "source": [
    "## One Proportion Testing in R\n",
    "As an example, you have an Easter basket full of candy, which is filled with both jelly beans and chocolate eggs. \n",
    "\n",
    "There are 15 jelly beans and 28 chocolate eggs, for a total of 43 different pieces of candy. \n",
    "\n",
    "You can use the function prop.test() to determine whether the proportion of jelly beans are equal to chocolate eggs \n",
    "\n",
    "- this would mean that they are both equal, or at 50% - probability of .5. To do this, you will use the argument x= to put in the number of jelly beans, \n",
    "\n",
    "and then the argument n= to specify the total number. You can also use the argument alternative= to specify whether you want a one-tailed or two-tailed test.\n",
    "\n",
    "You can use the statement of two.sided, greater, and less which would be the possibilities for a one-tailed test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3e0312d-91e8-4ee7-ac26-5c5603700f0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "\t1-sample proportions test with continuity correction\n",
       "\n",
       "data:  15 out of 43, null probability 0.5\n",
       "X-squared = 3.3488, df = 1, p-value = 0.03363\n",
       "alternative hypothesis: true p is less than 0.5\n",
       "95 percent confidence interval:\n",
       " 0.0000000 0.4858337\n",
       "sample estimates:\n",
       "        p \n",
       "0.3488372 \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prop.test(x = 15, n = 43, alternative = \"less\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a5980b1-1273-430d-8c67-f2e422f86f3c",
   "metadata": {},
   "source": [
    "The p value is .03, which means that the proportion of jelly beans to chocolate eggs is not equal, since it is different than .5 (half). \n",
    "\n",
    "If you're wondering what the proportion of jelly beans is to the whole, it is found in the bottom on the sample estimates:section: .34. \n",
    "\n",
    "This means that your Easter basket contains about 35% jelly beans and about 65% chocolate eggs. Hopefully you like chocolate!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "031a3db7-488d-4d23-ab56-9a81969aae49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Page 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f4c6ff-fd4d-434e-9531-974b7492736d",
   "metadata": {},
   "source": [
    "## Two Proportion Testing\n",
    "\n",
    "You will use a two proportion z test when you want to compare the proportions of two different categories to the whole."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a6bbe6-cae9-4222-9b8b-b5132346bffd",
   "metadata": {},
   "source": [
    "## Two Proportion Testing in R\n",
    "As an example, you will go back to your Easter basket full of candy, which is filled with both jelly beans and chocolate eggs. \n",
    "\n",
    "Each are available in several colors, and With a two proportion test, you can determine whether the proportions of those candies to the whole differ, as well as whether the proportion of the pink candies differ.\n",
    "\n",
    "There are 15 jelly beans and 28 chocolate eggs. Of the jelly beans, 7 are pink. Of the chocolate eggs, 12 are pink."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb9ea96-b063-4b92-b1fc-c905742f0726",
   "metadata": {},
   "source": [
    "You can again use the function prop.test() in R to test whether these are similar. \n",
    "\n",
    "You'll use the argument x= to feed in a vector of your first two proportions. \n",
    "\n",
    "These will be the smaller part of the whole. \n",
    "\n",
    "In this case, it's the number of candies from each type that are pink.\n",
    "\n",
    "Then you will feed in a argument of n= with the vector that includes the values of the total number of each type of candy. \n",
    "\n",
    "Lastly, you'll use the argument alternative= to choose whether you want a one-tailed or two-tailed test. \n",
    "\n",
    "Just like the one proportion test, you can use the statement of two.sided, greater, and less which would be the possibilities for a one-tailed test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1f199b9e-a272-4d4b-9f02-57a8e768e88a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "\t2-sample test for equality of proportions with continuity correction\n",
       "\n",
       "data:  c(7, 12) out of c(15, 28)\n",
       "X-squared = 7.5808e-32, df = 1, p-value = 1\n",
       "alternative hypothesis: two.sided\n",
       "95 percent confidence interval:\n",
       " -0.3119912  0.3881817\n",
       "sample estimates:\n",
       "   prop 1    prop 2 \n",
       "0.4666667 0.4285714 \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prop.test(x = c(7, 12), n = c(15, 28), alternative = \"two.sided\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d96a895-894b-4f86-b06b-ddd059acef30",
   "metadata": {},
   "source": [
    "The most important part of this output is the p value. In this case, your p value is 1, which means that the proportion of pink candies between jelly beans and chocolate are the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fe2d0b6e-c8c5-424c-b4d2-23e11dbd92e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Page 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819d56ea-6ee9-4403-a4b0-1c73cd73d071",
   "metadata": {},
   "source": [
    "## Independent Chi-Squares in R\n",
    "\n",
    "You recently learned how to conduct independent Chi-Squares in Python, and you already know how to compute them in MS Excel, so it's time to hit them up in R!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e381ed58-28f7-440c-ab46-75f8eefe11cb",
   "metadata": {},
   "source": [
    "In order to run independent Chi-Squares in R, you will need to install and load the library gmodels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790c01ce-b95d-408f-a8e7-17520d7c51d0",
   "metadata": {},
   "source": [
    "## Load in Data\n",
    "\n",
    "Next, you will read in your data. You'll be using survey data about the Star Wars movie franchise from over 1,000 participants. This data, as the name suggests on the zip file, has had all the columns renamed for your ease of use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b7556f5-a42b-4732-b133-0ae5c78e6a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "SW = read.csv('../../datasets/SW_survey_renamed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "309de9e5-3f9d-46b3-8870-127e7ad13fcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 6 × 38</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>RespondentID</th><th scope=col>SeenYN</th><th scope=col>FanYN</th><th scope=col>SeenIYN</th><th scope=col>SeenIIYN</th><th scope=col>SeenIIIYN</th><th scope=col>SeenIVYN</th><th scope=col>SeenVYN</th><th scope=col>SeenVIYN</th><th scope=col>RankI</th><th scope=col>...</th><th scope=col>Favorable_Yoda</th><th scope=col>ShotFirst</th><th scope=col>ExpandedUniverseYN</th><th scope=col>FanExpandedUniverseYN</th><th scope=col>StarTrekFanYN</th><th scope=col>Gender</th><th scope=col>Age</th><th scope=col>Household.Income</th><th scope=col>Education</th><th scope=col>Location</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>...</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>3292879998</td><td>Yes</td><td>Yes</td><td>Star Wars: Episode I  The Phantom Menace</td><td>Star Wars: Episode II  Attack of the Clones</td><td>Star Wars: Episode III  Revenge of the Sith</td><td>Star Wars: Episode IV  A New Hope</td><td>Star Wars: Episode V The Empire Strikes Back</td><td>Star Wars: Episode VI Return of the Jedi</td><td> 3</td><td>...</td><td>Very favorably    </td><td>I don't understand this question</td><td>Yes</td><td>No</td><td>No </td><td>Male</td><td>18-29</td><td>                   </td><td>High school degree              </td><td>South Atlantic    </td></tr>\n",
       "\t<tr><th scope=row>2</th><td>3292879538</td><td>No </td><td>   </td><td>                                        </td><td>                                           </td><td>                                           </td><td>                                 </td><td>                                            </td><td>                                        </td><td>NA</td><td>...</td><td>                  </td><td>                                </td><td>   </td><td>  </td><td>Yes</td><td>Male</td><td>18-29</td><td>$0 - $24,999       </td><td>Bachelor degree                 </td><td>West South Central</td></tr>\n",
       "\t<tr><th scope=row>3</th><td>3292765271</td><td>Yes</td><td>No </td><td>Star Wars: Episode I  The Phantom Menace</td><td>Star Wars: Episode II  Attack of the Clones</td><td>Star Wars: Episode III  Revenge of the Sith</td><td>                                 </td><td>                                            </td><td>                                        </td><td> 1</td><td>...</td><td>Unfamiliar (N/A)  </td><td>I don't understand this question</td><td>No </td><td>  </td><td>No </td><td>Male</td><td>18-29</td><td>$0 - $24,999       </td><td>High school degree              </td><td>West North Central</td></tr>\n",
       "\t<tr><th scope=row>4</th><td>3292763116</td><td>Yes</td><td>Yes</td><td>Star Wars: Episode I  The Phantom Menace</td><td>Star Wars: Episode II  Attack of the Clones</td><td>Star Wars: Episode III  Revenge of the Sith</td><td>Star Wars: Episode IV  A New Hope</td><td>Star Wars: Episode V The Empire Strikes Back</td><td>Star Wars: Episode VI Return of the Jedi</td><td> 5</td><td>...</td><td>Very favorably    </td><td>I don't understand this question</td><td>No </td><td>  </td><td>Yes</td><td>Male</td><td>18-29</td><td>$100,000 - $149,999</td><td>Some college or Associate degree</td><td>West North Central</td></tr>\n",
       "\t<tr><th scope=row>5</th><td>3292731220</td><td>Yes</td><td>Yes</td><td>Star Wars: Episode I  The Phantom Menace</td><td>Star Wars: Episode II  Attack of the Clones</td><td>Star Wars: Episode III  Revenge of the Sith</td><td>Star Wars: Episode IV  A New Hope</td><td>Star Wars: Episode V The Empire Strikes Back</td><td>Star Wars: Episode VI Return of the Jedi</td><td> 5</td><td>...</td><td>Somewhat favorably</td><td>Greedo                          </td><td>Yes</td><td>No</td><td>No </td><td>Male</td><td>18-29</td><td>$100,000 - $149,999</td><td>Some college or Associate degree</td><td>West North Central</td></tr>\n",
       "\t<tr><th scope=row>6</th><td>3292719380</td><td>Yes</td><td>Yes</td><td>Star Wars: Episode I  The Phantom Menace</td><td>Star Wars: Episode II  Attack of the Clones</td><td>Star Wars: Episode III  Revenge of the Sith</td><td>Star Wars: Episode IV  A New Hope</td><td>Star Wars: Episode V The Empire Strikes Back</td><td>Star Wars: Episode VI Return of the Jedi</td><td> 1</td><td>...</td><td>Very favorably    </td><td>Han                             </td><td>Yes</td><td>No</td><td>Yes</td><td>Male</td><td>18-29</td><td>$25,000 - $49,999  </td><td>Bachelor degree                 </td><td>Middle Atlantic   </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 6 × 38\n",
       "\\begin{tabular}{r|lllllllllllllllllllll}\n",
       "  & RespondentID & SeenYN & FanYN & SeenIYN & SeenIIYN & SeenIIIYN & SeenIVYN & SeenVYN & SeenVIYN & RankI & ... & Favorable\\_Yoda & ShotFirst & ExpandedUniverseYN & FanExpandedUniverseYN & StarTrekFanYN & Gender & Age & Household.Income & Education & Location\\\\\n",
       "  & <dbl> & <chr> & <chr> & <chr> & <chr> & <chr> & <chr> & <chr> & <chr> & <int> & ... & <chr> & <chr> & <chr> & <chr> & <chr> & <chr> & <chr> & <chr> & <chr> & <chr>\\\\\n",
       "\\hline\n",
       "\t1 & 3292879998 & Yes & Yes & Star Wars: Episode I  The Phantom Menace & Star Wars: Episode II  Attack of the Clones & Star Wars: Episode III  Revenge of the Sith & Star Wars: Episode IV  A New Hope & Star Wars: Episode V The Empire Strikes Back & Star Wars: Episode VI Return of the Jedi &  3 & ... & Very favorably     & I don't understand this question & Yes & No & No  & Male & 18-29 &                     & High school degree               & South Atlantic    \\\\\n",
       "\t2 & 3292879538 & No  &     &                                          &                                             &                                             &                                   &                                              &                                          & NA & ... &                    &                                  &     &    & Yes & Male & 18-29 & \\$0 - \\$24,999        & Bachelor degree                  & West South Central\\\\\n",
       "\t3 & 3292765271 & Yes & No  & Star Wars: Episode I  The Phantom Menace & Star Wars: Episode II  Attack of the Clones & Star Wars: Episode III  Revenge of the Sith &                                   &                                              &                                          &  1 & ... & Unfamiliar (N/A)   & I don't understand this question & No  &    & No  & Male & 18-29 & \\$0 - \\$24,999        & High school degree               & West North Central\\\\\n",
       "\t4 & 3292763116 & Yes & Yes & Star Wars: Episode I  The Phantom Menace & Star Wars: Episode II  Attack of the Clones & Star Wars: Episode III  Revenge of the Sith & Star Wars: Episode IV  A New Hope & Star Wars: Episode V The Empire Strikes Back & Star Wars: Episode VI Return of the Jedi &  5 & ... & Very favorably     & I don't understand this question & No  &    & Yes & Male & 18-29 & \\$100,000 - \\$149,999 & Some college or Associate degree & West North Central\\\\\n",
       "\t5 & 3292731220 & Yes & Yes & Star Wars: Episode I  The Phantom Menace & Star Wars: Episode II  Attack of the Clones & Star Wars: Episode III  Revenge of the Sith & Star Wars: Episode IV  A New Hope & Star Wars: Episode V The Empire Strikes Back & Star Wars: Episode VI Return of the Jedi &  5 & ... & Somewhat favorably & Greedo                           & Yes & No & No  & Male & 18-29 & \\$100,000 - \\$149,999 & Some college or Associate degree & West North Central\\\\\n",
       "\t6 & 3292719380 & Yes & Yes & Star Wars: Episode I  The Phantom Menace & Star Wars: Episode II  Attack of the Clones & Star Wars: Episode III  Revenge of the Sith & Star Wars: Episode IV  A New Hope & Star Wars: Episode V The Empire Strikes Back & Star Wars: Episode VI Return of the Jedi &  1 & ... & Very favorably     & Han                              & Yes & No & Yes & Male & 18-29 & \\$25,000 - \\$49,999   & Bachelor degree                  & Middle Atlantic   \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 6 × 38\n",
       "\n",
       "| <!--/--> | RespondentID &lt;dbl&gt; | SeenYN &lt;chr&gt; | FanYN &lt;chr&gt; | SeenIYN &lt;chr&gt; | SeenIIYN &lt;chr&gt; | SeenIIIYN &lt;chr&gt; | SeenIVYN &lt;chr&gt; | SeenVYN &lt;chr&gt; | SeenVIYN &lt;chr&gt; | RankI &lt;int&gt; | ... ... | Favorable_Yoda &lt;chr&gt; | ShotFirst &lt;chr&gt; | ExpandedUniverseYN &lt;chr&gt; | FanExpandedUniverseYN &lt;chr&gt; | StarTrekFanYN &lt;chr&gt; | Gender &lt;chr&gt; | Age &lt;chr&gt; | Household.Income &lt;chr&gt; | Education &lt;chr&gt; | Location &lt;chr&gt; |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| 1 | 3292879998 | Yes | Yes | Star Wars: Episode I  The Phantom Menace | Star Wars: Episode II  Attack of the Clones | Star Wars: Episode III  Revenge of the Sith | Star Wars: Episode IV  A New Hope | Star Wars: Episode V The Empire Strikes Back | Star Wars: Episode VI Return of the Jedi |  3 | ... | Very favorably     | I don't understand this question | Yes | No | No  | Male | 18-29 | <!----> | High school degree               | South Atlantic     |\n",
       "| 2 | 3292879538 | No  | <!----> | <!----> | <!----> | <!----> | <!----> | <!----> | <!----> | NA | ... | <!----> | <!----> | <!----> | <!----> | Yes | Male | 18-29 | $0 - $24,999        | Bachelor degree                  | West South Central |\n",
       "| 3 | 3292765271 | Yes | No  | Star Wars: Episode I  The Phantom Menace | Star Wars: Episode II  Attack of the Clones | Star Wars: Episode III  Revenge of the Sith | <!----> | <!----> | <!----> |  1 | ... | Unfamiliar (N/A)   | I don't understand this question | No  | <!----> | No  | Male | 18-29 | $0 - $24,999        | High school degree               | West North Central |\n",
       "| 4 | 3292763116 | Yes | Yes | Star Wars: Episode I  The Phantom Menace | Star Wars: Episode II  Attack of the Clones | Star Wars: Episode III  Revenge of the Sith | Star Wars: Episode IV  A New Hope | Star Wars: Episode V The Empire Strikes Back | Star Wars: Episode VI Return of the Jedi |  5 | ... | Very favorably     | I don't understand this question | No  | <!----> | Yes | Male | 18-29 | $100,000 - $149,999 | Some college or Associate degree | West North Central |\n",
       "| 5 | 3292731220 | Yes | Yes | Star Wars: Episode I  The Phantom Menace | Star Wars: Episode II  Attack of the Clones | Star Wars: Episode III  Revenge of the Sith | Star Wars: Episode IV  A New Hope | Star Wars: Episode V The Empire Strikes Back | Star Wars: Episode VI Return of the Jedi |  5 | ... | Somewhat favorably | Greedo                           | Yes | No | No  | Male | 18-29 | $100,000 - $149,999 | Some college or Associate degree | West North Central |\n",
       "| 6 | 3292719380 | Yes | Yes | Star Wars: Episode I  The Phantom Menace | Star Wars: Episode II  Attack of the Clones | Star Wars: Episode III  Revenge of the Sith | Star Wars: Episode IV  A New Hope | Star Wars: Episode V The Empire Strikes Back | Star Wars: Episode VI Return of the Jedi |  1 | ... | Very favorably     | Han                              | Yes | No | Yes | Male | 18-29 | $25,000 - $49,999   | Bachelor degree                  | Middle Atlantic    |\n",
       "\n"
      ],
      "text/plain": [
       "  RespondentID SeenYN FanYN SeenIYN                                 \n",
       "1 3292879998   Yes    Yes   Star Wars: Episode I  The Phantom Menace\n",
       "2 3292879538   No                                                   \n",
       "3 3292765271   Yes    No    Star Wars: Episode I  The Phantom Menace\n",
       "4 3292763116   Yes    Yes   Star Wars: Episode I  The Phantom Menace\n",
       "5 3292731220   Yes    Yes   Star Wars: Episode I  The Phantom Menace\n",
       "6 3292719380   Yes    Yes   Star Wars: Episode I  The Phantom Menace\n",
       "  SeenIIYN                                   \n",
       "1 Star Wars: Episode II  Attack of the Clones\n",
       "2                                            \n",
       "3 Star Wars: Episode II  Attack of the Clones\n",
       "4 Star Wars: Episode II  Attack of the Clones\n",
       "5 Star Wars: Episode II  Attack of the Clones\n",
       "6 Star Wars: Episode II  Attack of the Clones\n",
       "  SeenIIIYN                                   SeenIVYN                         \n",
       "1 Star Wars: Episode III  Revenge of the Sith Star Wars: Episode IV  A New Hope\n",
       "2                                                                              \n",
       "3 Star Wars: Episode III  Revenge of the Sith                                  \n",
       "4 Star Wars: Episode III  Revenge of the Sith Star Wars: Episode IV  A New Hope\n",
       "5 Star Wars: Episode III  Revenge of the Sith Star Wars: Episode IV  A New Hope\n",
       "6 Star Wars: Episode III  Revenge of the Sith Star Wars: Episode IV  A New Hope\n",
       "  SeenVYN                                     \n",
       "1 Star Wars: Episode V The Empire Strikes Back\n",
       "2                                             \n",
       "3                                             \n",
       "4 Star Wars: Episode V The Empire Strikes Back\n",
       "5 Star Wars: Episode V The Empire Strikes Back\n",
       "6 Star Wars: Episode V The Empire Strikes Back\n",
       "  SeenVIYN                                 RankI ... Favorable_Yoda    \n",
       "1 Star Wars: Episode VI Return of the Jedi  3    ... Very favorably    \n",
       "2                                          NA    ...                   \n",
       "3                                           1    ... Unfamiliar (N/A)  \n",
       "4 Star Wars: Episode VI Return of the Jedi  5    ... Very favorably    \n",
       "5 Star Wars: Episode VI Return of the Jedi  5    ... Somewhat favorably\n",
       "6 Star Wars: Episode VI Return of the Jedi  1    ... Very favorably    \n",
       "  ShotFirst                        ExpandedUniverseYN FanExpandedUniverseYN\n",
       "1 I don't understand this question Yes                No                   \n",
       "2                                                                          \n",
       "3 I don't understand this question No                                      \n",
       "4 I don't understand this question No                                      \n",
       "5 Greedo                           Yes                No                   \n",
       "6 Han                              Yes                No                   \n",
       "  StarTrekFanYN Gender Age   Household.Income   \n",
       "1 No            Male   18-29                    \n",
       "2 Yes           Male   18-29 $0 - $24,999       \n",
       "3 No            Male   18-29 $0 - $24,999       \n",
       "4 Yes           Male   18-29 $100,000 - $149,999\n",
       "5 No            Male   18-29 $100,000 - $149,999\n",
       "6 Yes           Male   18-29 $25,000 - $49,999  \n",
       "  Education                        Location          \n",
       "1 High school degree               South Atlantic    \n",
       "2 Bachelor degree                  West South Central\n",
       "3 High school degree               West North Central\n",
       "4 Some college or Associate degree West North Central\n",
       "5 Some college or Associate degree West North Central\n",
       "6 Bachelor degree                  Middle Atlantic   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "head(SW)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95abe0ae-f542-4489-8181-da02b061bc92",
   "metadata": {},
   "source": [
    "## Question Set Up\n",
    "\n",
    "One of the quintessential debates in Star Wars fandom is whether you are a fan of episodes I, II, and III (the newer, second trilogy of movies) \n",
    "\n",
    "or a fan of episodes IV, V, and VI (the older, beginning trilogy of movies). In this Chi-Square, you will determine whether age category Age influences someone's ranking of Episode I: The Phantom Menace."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98cd04f-3799-44f8-a9f1-f5a87636622c",
   "metadata": {},
   "source": [
    "## Data Wrangling\n",
    "\n",
    "This data is already formatted correctly for an independent Chi-Square."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb63d853-9204-4a6d-af56-437b9443b2f0",
   "metadata": {},
   "source": [
    "## Testing Assumptions and Running the Analysis\n",
    "\n",
    "There are two assumptions associated with independent Chi-Squares. The first is that you need to have independent data. \n",
    "\n",
    "This is just a theoretical requirement - each person or object must be able to fit in only one cell. \n",
    "\n",
    "The second is that your expected frequencies must be greater than 5 for each cell. \n",
    "\n",
    "You will be able to check this second assumption by running your Chi-Square and asking for expected frequencies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05813d46-0edb-43ed-ae51-dace6a268ea0",
   "metadata": {},
   "source": [
    "You will use the CrossTable() function from the gmodels library, and specify your IV followed by your DV. \n",
    "\n",
    "Then you can use the argument fisher=TRUE to specify that you want to use the Fisher's Exact Test method to calculate your effect size for Chi-Square, and the chisq=TRUE argument is to get the results from your Chi-Square. \n",
    "\n",
    "The next argument is the one of two that are required to get your expected frequencies. \n",
    "\n",
    "expected=TRUE will provide the expected frequencies, but you also need to include format=\"SPSS\" to get them printed out! \n",
    "\n",
    "This format mimics the output you would receive if you used the statistical program SPSS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9977c38c-06bd-4242-b341-aefc569d80ba",
   "metadata": {},
   "source": [
    "The last argument is sresid=TRUE, and this provides standardized residuals. Those will be used for determining effect sizes later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1eb50b2c-1c0e-4159-95da-2fae90b0f938",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in chisq.test(t, correct = FALSE, ...):\n",
      "\"Chi-squared approximation may be incorrect\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   Cell Contents\n",
      "|-------------------------|\n",
      "|                   Count |\n",
      "|         Expected Values |\n",
      "| Chi-square contribution |\n",
      "|             Row Percent |\n",
      "|          Column Percent |\n",
      "|           Total Percent |\n",
      "|            Std Residual |\n",
      "|-------------------------|\n",
      "\n",
      "Total Observations in Table:  835 \n",
      "\n",
      "             | SW$RankI \n",
      "      SW$Age |        1  |        2  |        3  |        4  |        5  |        6  | Row Total | \n",
      "-------------|-----------|-----------|-----------|-----------|-----------|-----------|-----------|\n",
      "             |        6  |        0  |        2  |        4  |        1  |        3  |       16  | \n",
      "             |    2.472  |    1.360  |    2.491  |    4.541  |    1.916  |    3.219  |           | \n",
      "             |    5.036  |    1.360  |    0.097  |    0.065  |    0.438  |    0.015  |           | \n",
      "             |   37.500% |    0.000% |   12.500% |   25.000% |    6.250% |   18.750% |    1.916% | \n",
      "             |    4.651% |    0.000% |    1.538% |    1.688% |    1.000% |    1.786% |           | \n",
      "             |    0.719% |    0.000% |    0.240% |    0.479% |    0.120% |    0.359% |           | \n",
      "             |    2.244  |   -1.166  |   -0.311  |   -0.254  |   -0.662  |   -0.122  |           | \n",
      "-------------|-----------|-----------|-----------|-----------|-----------|-----------|-----------|\n",
      "        > 60 |       53  |       22  |       36  |       50  |       13  |       18  |      192  | \n",
      "             |   29.662  |   16.326  |   29.892  |   54.496  |   22.994  |   38.630  |           | \n",
      "             |   18.362  |    1.972  |    1.248  |    0.371  |    4.344  |   11.017  |           | \n",
      "             |   27.604% |   11.458% |   18.750% |   26.042% |    6.771% |    9.375% |   22.994% | \n",
      "             |   41.085% |   30.986% |   27.692% |   21.097% |   13.000% |   10.714% |           | \n",
      "             |    6.347% |    2.635% |    4.311% |    5.988% |    1.557% |    2.156% |           | \n",
      "             |    4.285  |    1.404  |    1.117  |   -0.609  |   -2.084  |   -3.319  |           | \n",
      "-------------|-----------|-----------|-----------|-----------|-----------|-----------|-----------|\n",
      "       18-29 |       21  |       15  |       20  |       42  |       33  |       49  |      180  | \n",
      "             |   27.808  |   15.305  |   28.024  |   51.090  |   21.557  |   36.216  |           | \n",
      "             |    1.667  |    0.006  |    2.297  |    1.617  |    6.074  |    4.513  |           | \n",
      "             |   11.667% |    8.333% |   11.111% |   23.333% |   18.333% |   27.222% |   21.557% | \n",
      "             |   16.279% |   21.127% |   15.385% |   17.722% |   33.000% |   29.167% |           | \n",
      "             |    2.515% |    1.796% |    2.395% |    5.030% |    3.952% |    5.868% |           | \n",
      "             |   -1.291  |   -0.078  |   -1.516  |   -1.272  |    2.465  |    2.124  |           | \n",
      "-------------|-----------|-----------|-----------|-----------|-----------|-----------|-----------|\n",
      "       30-44 |       15  |       11  |       28  |       57  |       25  |       71  |      207  | \n",
      "             |   31.980  |   17.601  |   32.228  |   58.753  |   24.790  |   41.648  |           | \n",
      "             |    9.015  |    2.476  |    0.555  |    0.052  |    0.002  |   20.686  |           | \n",
      "             |    7.246% |    5.314% |   13.527% |   27.536% |   12.077% |   34.300% |   24.790% | \n",
      "             |   11.628% |   15.493% |   21.538% |   24.051% |   25.000% |   42.262% |           | \n",
      "             |    1.796% |    1.317% |    3.353% |    6.826% |    2.994% |    8.503% |           | \n",
      "             |   -3.003  |   -1.573  |   -0.745  |   -0.229  |    0.042  |    4.548  |           | \n",
      "-------------|-----------|-----------|-----------|-----------|-----------|-----------|-----------|\n",
      "       45-60 |       34  |       23  |       44  |       84  |       28  |       27  |      240  | \n",
      "             |   37.078  |   20.407  |   37.365  |   68.120  |   28.743  |   48.287  |           | \n",
      "             |    0.255  |    0.329  |    1.178  |    3.702  |    0.019  |    9.385  |           | \n",
      "             |   14.167% |    9.583% |   18.333% |   35.000% |   11.667% |   11.250% |   28.743% | \n",
      "             |   26.357% |   32.394% |   33.846% |   35.443% |   28.000% |   16.071% |           | \n",
      "             |    4.072% |    2.754% |    5.269% |   10.060% |    3.353% |    3.234% |           | \n",
      "             |   -0.505  |    0.574  |    1.085  |    1.924  |   -0.138  |   -3.063  |           | \n",
      "-------------|-----------|-----------|-----------|-----------|-----------|-----------|-----------|\n",
      "Column Total |      129  |       71  |      130  |      237  |      100  |      168  |      835  | \n",
      "             |   15.449% |    8.503% |   15.569% |   28.383% |   11.976% |   20.120% |           | \n",
      "-------------|-----------|-----------|-----------|-----------|-----------|-----------|-----------|\n",
      "\n",
      " \n",
      "Statistics for All Table Factors\n",
      "\n",
      "\n",
      "Pearson's Chi-squared test \n",
      "------------------------------------------------------------\n",
      "Chi^2 =  108.1543     d.f. =  20     p =  4.257807e-14 \n",
      "\n",
      "\n",
      " \n"
     ]
    },
    {
     "ename": "ERROR",
     "evalue": "Error in fisher.test(t, alternative = \"two.sided\"): FEXACT error 501.\nThe hash table key cannot be computed because the largest key\nis larger than the largest representable int.\nThe algorithm cannot proceed.\nReduce the workspace, consider using 'simulate.p.value=TRUE' or another algorithm.\n",
     "output_type": "error",
     "traceback": [
      "Error in fisher.test(t, alternative = \"two.sided\"): FEXACT error 501.\nThe hash table key cannot be computed because the largest key\nis larger than the largest representable int.\nThe algorithm cannot proceed.\nReduce the workspace, consider using 'simulate.p.value=TRUE' or another algorithm.\nTraceback:\n",
      "1. CrossTable(SW$Age, SW$RankI, fisher = TRUE, chisq = TRUE, expected = TRUE, \n .     sresid = TRUE, format = \"SPSS\")",
      "2. print.statistics()",
      "3. fisher.test(t, alternative = \"two.sided\")"
     ]
    }
   ],
   "source": [
    "CrossTable(SW$Age, SW$RankI, fisher=TRUE, chisq = TRUE, expected = TRUE, sresid=TRUE, format=\"SPSS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b02edb3-2a85-4040-a5ab-3092c77d0fef",
   "metadata": {},
   "source": [
    "The very first output provides you a guide to each individual cell. First you'll see the actual count, then you will see the expected values, then the Chi-Square contribution, then Row Percent, Column Percent, Total Percent, and your standardized residual."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c430cee-4603-405d-945b-67ea163ba3d9",
   "metadata": {},
   "source": [
    "## Check Assumption of Expected Frequencies\n",
    "\n",
    "You will want to look in the second row in each cell to find the expected frequency. \n",
    "\n",
    "Ideally, you want to have the expected value greater than 5 for each cell, but that's a pipe dream typically. \n",
    "\n",
    "You are technically allowed to have 20% of your cells with 5 or less, as long as none of them are zero. \n",
    "\n",
    "Luckily, you have no zeros here, and it looks like although there are some cells that have values less than five, only 6/30 have that, \n",
    "\n",
    "which happens to be 20%! So you are golden, and meet the assumption for Chi-Square. You can now proceed to interpret your results!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc4c833-d8e0-44af-aa22-41aa01226b70",
   "metadata": {},
   "source": [
    "## Interpret Results\n",
    "\n",
    "The results are shown at the bottom of your output, under the heading Pearson's Chi-squared test. \n",
    "\n",
    "If the p value is less than .05, than this analysis is significant, meaning that age does in fact make a difference in how people rank Episode I."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9a71324e-7544-41e4-91ad-acb519d79437",
   "metadata": {},
   "outputs": [],
   "source": [
    "## p-value is significant, age does influce rank of Ep. 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a8c82c-1fb1-4f36-861b-144cdd556e95",
   "metadata": {},
   "source": [
    "## Post Hocs\n",
    "\n",
    "You may be wondering HOW age influences rankings for Episode I. \n",
    "\n",
    "The way you can do this is through a post hoc analysis, which will help you determine where those differences lie. \n",
    "\n",
    "With a Chi-Square, the way you will interpret your significant findings with a post hoc is with the standardized residual, which is located on the very bottom of the cell. \n",
    "\n",
    "As a general rule, anything that has a standardized residual with an absolute value greater than or equal to two is significantly different than what you expected. \n",
    "\n",
    "It is greater than expected if there is a plus sign, and it is less than expected if there is a minus sign. Looking at the results above, you can see the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4797dd-ec15-4eb3-8fc1-495e2962d864",
   "metadata": {},
   "source": [
    "* More people who did not disclose their age ranked Episode I first than expected\n",
    "\n",
    "* More people aged over 60 ranked Episode I first than expected\n",
    "\n",
    "* Fewer people aged over 60 ranked Episode I fifth or sixth than expected\n",
    "\n",
    "* More people aged 18-29 ranked Episode I fifth or sixth than expected\n",
    "\n",
    "* Fewer people aged 30-44 ranked Episode I first than expected\n",
    "\n",
    "* More people aged 30-44 ranked Episode I sixth than expected\n",
    "\n",
    "* Fewer people aged 45-60 ranked Episode I sixth than expected\n",
    "\n",
    "Now, if you were to write this all out and present upon it at a business, you will get laughed out of the house, or even worse, completely ignored. \n",
    "\n",
    "So you'll need to summarize things and put them in layman's terms. Maybe something like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304b6f67-6d23-4fa4-9838-6928b6138987",
   "metadata": {},
   "source": [
    "People either loved or hated Episode I.  Those who did not disclose their age, those who were 30-44 or over 60 years old were more likely to rank Episode I as their favorite. Those over 45 years old were less likely to to rank Episode I as their least favorite, and those over 60 years old were less likely to rank Episode I fifth. Those in the 30-44 year old age group were more likely to rank Episode I last, however."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cd3b2492-85de-4264-b93d-2c898ca5dbe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Page 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbedc365-ca44-46ed-a414-e860ccb9cd92",
   "metadata": {},
   "source": [
    "## Goodness of Fit Chi-Squares in R\n",
    "\n",
    "\n",
    "You will use a goodness of fit Chi-Square when you are trying to compare a sample to a population. It is similar in concept to the single sample t-test."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c32ab6a-c634-4a0d-a436-66418f9e56ec",
   "metadata": {},
   "source": [
    "## Load in Libraries\n",
    "\n",
    "To compute a goodness of fit Chi-Square, the only package you will need is dplyr, to count up your data.\n",
    "\n",
    "dplyr is included in tidyverse, which we loaded earlier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7f987d-1ad7-4078-b988-5cb923476902",
   "metadata": {},
   "source": [
    "## Question Set Up\n",
    "\n",
    "\n",
    "You found something online that mentioned that 90% of people are Star Wars fans, and you want to see if that holds true in your own survey. \n",
    "\n",
    "In this way, you are comparing your sample (the survey) to the population at large (what you read online)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6013a05-9860-4985-bc03-9776624a96bf",
   "metadata": {},
   "source": [
    "## Data Wrangling\n",
    "\n",
    "In order to run a goodness of fit Chi-Square, you need the observed values for folks who are fans of Star Wars, and for folks who are not fans of Star Wars. \n",
    "    \n",
    "You can easily get those values by aggregating your data using the dplyr summarize() function for count (n()):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a8d88e1f-42f0-457f-9a5b-827ca3ab6253",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A tibble: 3 × 2</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>FanYN</th><th scope=col>count</th></tr>\n",
       "\t<tr><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;int&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>   </td><td>350</td></tr>\n",
       "\t<tr><td>No </td><td>284</td></tr>\n",
       "\t<tr><td>Yes</td><td>552</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A tibble: 3 × 2\n",
       "\\begin{tabular}{ll}\n",
       " FanYN & count\\\\\n",
       " <chr> & <int>\\\\\n",
       "\\hline\n",
       "\t     & 350\\\\\n",
       "\t No  & 284\\\\\n",
       "\t Yes & 552\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A tibble: 3 × 2\n",
       "\n",
       "| FanYN &lt;chr&gt; | count &lt;int&gt; |\n",
       "|---|---|\n",
       "| <!----> | 350 |\n",
       "| No  | 284 |\n",
       "| Yes | 552 |\n",
       "\n"
      ],
      "text/plain": [
       "  FanYN count\n",
       "1       350  \n",
       "2 No    284  \n",
       "3 Yes   552  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "SW %>% group_by(FanYN) %>% summarize(count = n())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e46789-0a3e-463e-9596-8cb733859ec5",
   "metadata": {},
   "source": [
    "You can ignore the missing values in this case, but you'll want to take note of the number of Nos and the number of Yess."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67cf46ab-35b4-4b0c-a7d0-2cf3ce11020c",
   "metadata": {},
   "source": [
    "## Run Analysis\n",
    "\n",
    "Now you are ready to set up for your analysis!\n",
    "\n",
    "You will want to define the observed values as vectors, which you got from above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8aa1e06e-d4e8-4d4d-add6-a837603677ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "observed = c(552, 284)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003add75-6115-4894-b373-f7d1fc844a2a",
   "metadata": {},
   "source": [
    "Next, you will define a vector of your expected values. These expected values must equal 1. If they don't, you end up with this error when you eventually run your Chi-Square:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48994ad8-2470-466c-8a97-988c8ac666ca",
   "metadata": {},
   "source": [
    "'''Error in chisq.test(x = observed, p = expected) : \n",
    "  probabilities must sum to 1.'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6b87c4-0194-410c-a0f4-ac27122930d8",
   "metadata": {},
   "source": [
    "Here is how you will define your expected values. Since you are comparing to the online estimate of 90% Star Wars fans, you will want the Star Wars fans to come first (to match the above, which started with the number of yesses) and you will change 90% to .90:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "369c5566-cf01-4f1f-975b-c71ea1b188ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "expected = c(0.90, 0.10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77eec398-8371-43a2-91e1-fa5327ac9bfb",
   "metadata": {},
   "source": [
    "And now you are ready to run the analysis itself, with the function chisq.test(), in which you will define the argument of x= with your observed frequencies, and in which you will define the argument of p= with your expected frequencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "16ba618c-be70-4d7c-ac6d-fefcba298b6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "\tChi-squared test for given probabilities\n",
       "\n",
       "data:  observed\n",
       "X-squared = 533.76, df = 1, p-value < 2.2e-16\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "chisq.test(x = observed, p = expected)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844a9bb1-1eda-48c9-a21f-177adb9b616c",
   "metadata": {},
   "source": [
    "If the p value is less than .05, than your observed and expected values differ. In this case, this means that the number of Star Wars fans is not 90%. You might conclude, then, that your sample is somewhat confused compared to the overall population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e21c8aa3-070c-45d7-bfb6-d895819f35de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Page 9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bcb08d5-cd94-470f-8409-7a19f203d683",
   "metadata": {},
   "source": [
    "## McNemar Chi-Squares\n",
    "\n",
    "The McNemar Chi-Square is used when you are trying to look at something over time, and have only two timepoints; maybe a pre and a post. \n",
    "\n",
    "The timepoints are your independent variable. You are also limited to two levels of your dependent variable. \n",
    "\n",
    "You can think of a McNemar Chi-Square like a dependent t-test for categorical data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ecedd66-e457-4e57-8fbf-fa3c959d5451",
   "metadata": {},
   "source": [
    "## Load in Libraries\n",
    "\n",
    "In order to complete McNemar Chi-Squares in R, the only libraries you will need are gmodels to conduct the Chi-Square, and tidyr to do some data wrangling (though you might not always need to wrangle your data).\n",
    "\n",
    "tidyr is a part of tidyverse, which we loaded earlier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09116fa-71d0-4523-b29c-6b55282dcf8d",
   "metadata": {},
   "source": [
    "## Load in Data\n",
    "\n",
    "The data you'll be using comes from the sales records of a bakery. It has the date and time of each bakery item sold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2711c6ec-9b04-4ecd-8212-42c8e266dda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "bakerySales = read.csv('../../datasets/bakery_sales.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f24e865e-f077-416e-8bbd-08effb48c27d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 6 × 4</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>Date</th><th scope=col>Time</th><th scope=col>Transaction</th><th scope=col>Item</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;chr&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>10/30/2016</td><td>9:58:11 AM </td><td>1</td><td>Bread        </td></tr>\n",
       "\t<tr><th scope=row>2</th><td>10/30/2016</td><td>10:05:34 AM</td><td>2</td><td>Scandinavian </td></tr>\n",
       "\t<tr><th scope=row>3</th><td>10/30/2016</td><td>10:05:34 AM</td><td>2</td><td>Scandinavian </td></tr>\n",
       "\t<tr><th scope=row>4</th><td>10/30/2016</td><td>10:07:57 AM</td><td>3</td><td>Hot chocolate</td></tr>\n",
       "\t<tr><th scope=row>5</th><td>10/30/2016</td><td>10:07:57 AM</td><td>3</td><td>Jam          </td></tr>\n",
       "\t<tr><th scope=row>6</th><td>10/30/2016</td><td>10:07:57 AM</td><td>3</td><td>Cookies      </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 6 × 4\n",
       "\\begin{tabular}{r|llll}\n",
       "  & Date & Time & Transaction & Item\\\\\n",
       "  & <chr> & <chr> & <int> & <chr>\\\\\n",
       "\\hline\n",
       "\t1 & 10/30/2016 & 9:58:11 AM  & 1 & Bread        \\\\\n",
       "\t2 & 10/30/2016 & 10:05:34 AM & 2 & Scandinavian \\\\\n",
       "\t3 & 10/30/2016 & 10:05:34 AM & 2 & Scandinavian \\\\\n",
       "\t4 & 10/30/2016 & 10:07:57 AM & 3 & Hot chocolate\\\\\n",
       "\t5 & 10/30/2016 & 10:07:57 AM & 3 & Jam          \\\\\n",
       "\t6 & 10/30/2016 & 10:07:57 AM & 3 & Cookies      \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 6 × 4\n",
       "\n",
       "| <!--/--> | Date &lt;chr&gt; | Time &lt;chr&gt; | Transaction &lt;int&gt; | Item &lt;chr&gt; |\n",
       "|---|---|---|---|---|\n",
       "| 1 | 10/30/2016 | 9:58:11 AM  | 1 | Bread         |\n",
       "| 2 | 10/30/2016 | 10:05:34 AM | 2 | Scandinavian  |\n",
       "| 3 | 10/30/2016 | 10:05:34 AM | 2 | Scandinavian  |\n",
       "| 4 | 10/30/2016 | 10:07:57 AM | 3 | Hot chocolate |\n",
       "| 5 | 10/30/2016 | 10:07:57 AM | 3 | Jam           |\n",
       "| 6 | 10/30/2016 | 10:07:57 AM | 3 | Cookies       |\n",
       "\n"
      ],
      "text/plain": [
       "  Date       Time        Transaction Item         \n",
       "1 10/30/2016 9:58:11 AM  1           Bread        \n",
       "2 10/30/2016 10:05:34 AM 2           Scandinavian \n",
       "3 10/30/2016 10:05:34 AM 2           Scandinavian \n",
       "4 10/30/2016 10:07:57 AM 3           Hot chocolate\n",
       "5 10/30/2016 10:07:57 AM 3           Jam          \n",
       "6 10/30/2016 10:07:57 AM 3           Cookies      "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "head(bakerySales)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508a6dc6-d782-493e-b999-79277ac1362b",
   "metadata": {},
   "source": [
    "## Question Set Up\n",
    "\n",
    "You will be answering the following question:\n",
    "\n",
    "Do the sales of coffee change from the beginning of the month to the end of the month?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e758ed69-3446-4aff-b73a-e1165ba568d4",
   "metadata": {},
   "source": [
    "## Data Wrangling\n",
    "\n",
    "Looking at your data, you will find that you only have a single Date variable, and that you only have a single Item variable. \n",
    "\n",
    "Date is not broken up yet into the beginning and the end of the month, and Item is not broken into coffee or other. \n",
    "\n",
    "So, you will need to do a bit of recoding!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96547a3-e15d-4bbc-9001-60105f2563c3",
   "metadata": {},
   "source": [
    "## Check the Structure of Your Data\n",
    "\n",
    "First, it's always a good idea to check the structure of your data. You can use the str() function to do so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8c158aff-8492-4e9a-b55b-4b7482108711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'data.frame':\t21293 obs. of  4 variables:\n",
      " $ Date       : chr  \"10/30/2016\" \"10/30/2016\" \"10/30/2016\" \"10/30/2016\" ...\n",
      " $ Time       : chr  \"9:58:11 AM\" \"10:05:34 AM\" \"10:05:34 AM\" \"10:07:57 AM\" ...\n",
      " $ Transaction: int  1 2 2 3 3 3 4 5 5 5 ...\n",
      " $ Item       : chr  \"Bread\" \"Scandinavian\" \"Scandinavian\" \"Hot chocolate\" ...\n"
     ]
    }
   ],
   "source": [
    "str(bakerySales)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe000078-33c5-43eb-a1a7-2c1e244a06aa",
   "metadata": {},
   "source": [
    "The first thing that you should notice here is that your Date column is not formatted as a date, and you will need to do that before going farther."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40e1e63-689d-4239-80f2-568f65a2bce0",
   "metadata": {},
   "source": [
    "## Reformatting to a Date\n",
    "\n",
    "Reformatting to a date can be done with the function as.Date():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a303752d-6404-4a68-bf6e-869edc0608ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "bakerySales$DateR = as.Date(bakerySales$Date, format = '%m/%d/%Y')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba81561-09b3-47f1-aeea-cc1fb020627b",
   "metadata": {},
   "source": [
    "You can specify that this be a new variable by putting a new name at the front before the =, and then you'll use the function as.Date(). Specify the original variable you are formatting as a date, and then you'll need to use the argument format= to specify how the date has come in. Remember that the format needs to match the data exactly. The %m is for a decimal month, the %d is for a decimal day, and the %Y is for a four-digit year. You will notice that they are all separated by a / because that is how the data are separated in the orginal column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a920706e-81e0-446c-9270-d5fc0b601a2a",
   "metadata": {},
   "source": [
    "## Separating the Pieces of the Date Variable\n",
    "\n",
    "Once that is done, you will want to separate this out, so that you can look at and recode the Day column individually. You'll utilize the separate() function from the tidyr package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "97eef174-79aa-4ff2-a7da-424d2bd9fef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "bakerySales1 <- separate(bakerySales, DateR, c(\"Year\", \"Month\", \"Day\"), sep=\"-\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a67dd45e-0bc4-47d0-83a1-99bc45b92606",
   "metadata": {},
   "source": [
    "And the result is that you now have month, day, and year, all split out in your dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "dd31eab4-4964-449b-95d8-8cb51ee0471f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 6 × 7</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>Date</th><th scope=col>Time</th><th scope=col>Transaction</th><th scope=col>Item</th><th scope=col>Year</th><th scope=col>Month</th><th scope=col>Day</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>10/30/2016</td><td>9:58:11 AM </td><td>1</td><td>Bread        </td><td>2016</td><td>10</td><td>30</td></tr>\n",
       "\t<tr><th scope=row>2</th><td>10/30/2016</td><td>10:05:34 AM</td><td>2</td><td>Scandinavian </td><td>2016</td><td>10</td><td>30</td></tr>\n",
       "\t<tr><th scope=row>3</th><td>10/30/2016</td><td>10:05:34 AM</td><td>2</td><td>Scandinavian </td><td>2016</td><td>10</td><td>30</td></tr>\n",
       "\t<tr><th scope=row>4</th><td>10/30/2016</td><td>10:07:57 AM</td><td>3</td><td>Hot chocolate</td><td>2016</td><td>10</td><td>30</td></tr>\n",
       "\t<tr><th scope=row>5</th><td>10/30/2016</td><td>10:07:57 AM</td><td>3</td><td>Jam          </td><td>2016</td><td>10</td><td>30</td></tr>\n",
       "\t<tr><th scope=row>6</th><td>10/30/2016</td><td>10:07:57 AM</td><td>3</td><td>Cookies      </td><td>2016</td><td>10</td><td>30</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 6 × 7\n",
       "\\begin{tabular}{r|lllllll}\n",
       "  & Date & Time & Transaction & Item & Year & Month & Day\\\\\n",
       "  & <chr> & <chr> & <int> & <chr> & <chr> & <chr> & <chr>\\\\\n",
       "\\hline\n",
       "\t1 & 10/30/2016 & 9:58:11 AM  & 1 & Bread         & 2016 & 10 & 30\\\\\n",
       "\t2 & 10/30/2016 & 10:05:34 AM & 2 & Scandinavian  & 2016 & 10 & 30\\\\\n",
       "\t3 & 10/30/2016 & 10:05:34 AM & 2 & Scandinavian  & 2016 & 10 & 30\\\\\n",
       "\t4 & 10/30/2016 & 10:07:57 AM & 3 & Hot chocolate & 2016 & 10 & 30\\\\\n",
       "\t5 & 10/30/2016 & 10:07:57 AM & 3 & Jam           & 2016 & 10 & 30\\\\\n",
       "\t6 & 10/30/2016 & 10:07:57 AM & 3 & Cookies       & 2016 & 10 & 30\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 6 × 7\n",
       "\n",
       "| <!--/--> | Date &lt;chr&gt; | Time &lt;chr&gt; | Transaction &lt;int&gt; | Item &lt;chr&gt; | Year &lt;chr&gt; | Month &lt;chr&gt; | Day &lt;chr&gt; |\n",
       "|---|---|---|---|---|---|---|---|\n",
       "| 1 | 10/30/2016 | 9:58:11 AM  | 1 | Bread         | 2016 | 10 | 30 |\n",
       "| 2 | 10/30/2016 | 10:05:34 AM | 2 | Scandinavian  | 2016 | 10 | 30 |\n",
       "| 3 | 10/30/2016 | 10:05:34 AM | 2 | Scandinavian  | 2016 | 10 | 30 |\n",
       "| 4 | 10/30/2016 | 10:07:57 AM | 3 | Hot chocolate | 2016 | 10 | 30 |\n",
       "| 5 | 10/30/2016 | 10:07:57 AM | 3 | Jam           | 2016 | 10 | 30 |\n",
       "| 6 | 10/30/2016 | 10:07:57 AM | 3 | Cookies       | 2016 | 10 | 30 |\n",
       "\n"
      ],
      "text/plain": [
       "  Date       Time        Transaction Item          Year Month Day\n",
       "1 10/30/2016 9:58:11 AM  1           Bread         2016 10    30 \n",
       "2 10/30/2016 10:05:34 AM 2           Scandinavian  2016 10    30 \n",
       "3 10/30/2016 10:05:34 AM 2           Scandinavian  2016 10    30 \n",
       "4 10/30/2016 10:07:57 AM 3           Hot chocolate 2016 10    30 \n",
       "5 10/30/2016 10:07:57 AM 3           Jam           2016 10    30 \n",
       "6 10/30/2016 10:07:57 AM 3           Cookies       2016 10    30 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "head(bakerySales1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208e2e4c-55c9-4500-bc97-762af7df3f22",
   "metadata": {},
   "source": [
    "## Recoding to Beginning or End of Month\n",
    "\n",
    "Now that you have Day separated from the pack, you can see to the recoding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "dac24bf8-460a-40e7-9369-3923e2e46af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "bakerySales1$DayR <- NA\n",
    "bakerySales1$DayR[bakerySales1$Day <= 15] <- 0\n",
    "bakerySales1$DayR[bakerySales1$Day > 15] <- 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff00843-473a-49d9-959e-2dec67519085",
   "metadata": {},
   "source": [
    "This code first opens up a new variable named DayR, and then splits the content in half. Anything that is on the 15th of the month or earlier is recoded as a zero, while anything on the 16th of the month or later will be recoded as a one."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac420c24-66d7-40e5-9741-479adb24a707",
   "metadata": {},
   "source": [
    "## Recoding to Coffee or Other\n",
    "\n",
    "The last recode you have left to undertake is to recode the Item variable from listing every single item out to recoding into the discrete categories of coffee or not coffee. \n",
    "\n",
    "Below, you'll find code that creates a new variable named CoffeeSales and fills it with a 1 for anything that is Coffee and fills it with a 0 for anything that is not coffee."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d780087f-0e23-4f2a-9796-3bf975f773e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "bakerySales1$CoffeeSales <- NA\n",
    "bakerySales1$CoffeeSales[bakerySales1$Item == \"Coffee\"] <- 1\n",
    "bakerySales1$CoffeeSales[bakerySales1$Item != \"Coffee\"] <- 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547ce421-b1f0-4292-b61c-da9b13fcc37e",
   "metadata": {},
   "source": [
    "And with that, you are now ready to launch into your assumption testing and analysis!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "34e36483-e524-4993-917d-9417b5150101",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 6 × 9</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>Date</th><th scope=col>Time</th><th scope=col>Transaction</th><th scope=col>Item</th><th scope=col>Year</th><th scope=col>Month</th><th scope=col>Day</th><th scope=col>DayR</th><th scope=col>CoffeeSales</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>10/30/2016</td><td>9:58:11 AM </td><td>1</td><td>Bread        </td><td>2016</td><td>10</td><td>30</td><td>1</td><td>0</td></tr>\n",
       "\t<tr><th scope=row>2</th><td>10/30/2016</td><td>10:05:34 AM</td><td>2</td><td>Scandinavian </td><td>2016</td><td>10</td><td>30</td><td>1</td><td>0</td></tr>\n",
       "\t<tr><th scope=row>3</th><td>10/30/2016</td><td>10:05:34 AM</td><td>2</td><td>Scandinavian </td><td>2016</td><td>10</td><td>30</td><td>1</td><td>0</td></tr>\n",
       "\t<tr><th scope=row>4</th><td>10/30/2016</td><td>10:07:57 AM</td><td>3</td><td>Hot chocolate</td><td>2016</td><td>10</td><td>30</td><td>1</td><td>0</td></tr>\n",
       "\t<tr><th scope=row>5</th><td>10/30/2016</td><td>10:07:57 AM</td><td>3</td><td>Jam          </td><td>2016</td><td>10</td><td>30</td><td>1</td><td>0</td></tr>\n",
       "\t<tr><th scope=row>6</th><td>10/30/2016</td><td>10:07:57 AM</td><td>3</td><td>Cookies      </td><td>2016</td><td>10</td><td>30</td><td>1</td><td>0</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 6 × 9\n",
       "\\begin{tabular}{r|lllllllll}\n",
       "  & Date & Time & Transaction & Item & Year & Month & Day & DayR & CoffeeSales\\\\\n",
       "  & <chr> & <chr> & <int> & <chr> & <chr> & <chr> & <chr> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t1 & 10/30/2016 & 9:58:11 AM  & 1 & Bread         & 2016 & 10 & 30 & 1 & 0\\\\\n",
       "\t2 & 10/30/2016 & 10:05:34 AM & 2 & Scandinavian  & 2016 & 10 & 30 & 1 & 0\\\\\n",
       "\t3 & 10/30/2016 & 10:05:34 AM & 2 & Scandinavian  & 2016 & 10 & 30 & 1 & 0\\\\\n",
       "\t4 & 10/30/2016 & 10:07:57 AM & 3 & Hot chocolate & 2016 & 10 & 30 & 1 & 0\\\\\n",
       "\t5 & 10/30/2016 & 10:07:57 AM & 3 & Jam           & 2016 & 10 & 30 & 1 & 0\\\\\n",
       "\t6 & 10/30/2016 & 10:07:57 AM & 3 & Cookies       & 2016 & 10 & 30 & 1 & 0\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 6 × 9\n",
       "\n",
       "| <!--/--> | Date &lt;chr&gt; | Time &lt;chr&gt; | Transaction &lt;int&gt; | Item &lt;chr&gt; | Year &lt;chr&gt; | Month &lt;chr&gt; | Day &lt;chr&gt; | DayR &lt;dbl&gt; | CoffeeSales &lt;dbl&gt; |\n",
       "|---|---|---|---|---|---|---|---|---|---|\n",
       "| 1 | 10/30/2016 | 9:58:11 AM  | 1 | Bread         | 2016 | 10 | 30 | 1 | 0 |\n",
       "| 2 | 10/30/2016 | 10:05:34 AM | 2 | Scandinavian  | 2016 | 10 | 30 | 1 | 0 |\n",
       "| 3 | 10/30/2016 | 10:05:34 AM | 2 | Scandinavian  | 2016 | 10 | 30 | 1 | 0 |\n",
       "| 4 | 10/30/2016 | 10:07:57 AM | 3 | Hot chocolate | 2016 | 10 | 30 | 1 | 0 |\n",
       "| 5 | 10/30/2016 | 10:07:57 AM | 3 | Jam           | 2016 | 10 | 30 | 1 | 0 |\n",
       "| 6 | 10/30/2016 | 10:07:57 AM | 3 | Cookies       | 2016 | 10 | 30 | 1 | 0 |\n",
       "\n"
      ],
      "text/plain": [
       "  Date       Time        Transaction Item          Year Month Day DayR\n",
       "1 10/30/2016 9:58:11 AM  1           Bread         2016 10    30  1   \n",
       "2 10/30/2016 10:05:34 AM 2           Scandinavian  2016 10    30  1   \n",
       "3 10/30/2016 10:05:34 AM 2           Scandinavian  2016 10    30  1   \n",
       "4 10/30/2016 10:07:57 AM 3           Hot chocolate 2016 10    30  1   \n",
       "5 10/30/2016 10:07:57 AM 3           Jam           2016 10    30  1   \n",
       "6 10/30/2016 10:07:57 AM 3           Cookies       2016 10    30  1   \n",
       "  CoffeeSales\n",
       "1 0          \n",
       "2 0          \n",
       "3 0          \n",
       "4 0          \n",
       "5 0          \n",
       "6 0          "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "head(bakerySales1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc97dd23-325c-403c-92af-06eb3707e863",
   "metadata": {},
   "source": [
    "## Test Assumptions and Run Analyses\n",
    "\n",
    "The assumptions for a McNemar Chi-Square is the same as for an independent Chi-Square: you need to have at least 5 expected observations in each cell. \n",
    "    \n",
    "And just like the independent Chi-Square, in R, you will need to run the entire analysis first and then check the assumption. \n",
    "\n",
    "All the code is nearly the same, too, except that you will add in the argument of mcnemar=TRUE. Take a look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3049d11c-2be2-40ca-b0dd-aa71bf7fd22a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   Cell Contents\n",
      "|-------------------------|\n",
      "|                   Count |\n",
      "|         Expected Values |\n",
      "| Chi-square contribution |\n",
      "|             Row Percent |\n",
      "|          Column Percent |\n",
      "|           Total Percent |\n",
      "|            Std Residual |\n",
      "|-------------------------|\n",
      "\n",
      "Total Observations in Table:  21293 \n",
      "\n",
      "                  | bakerySales1$CoffeeSales \n",
      "bakerySales1$DayR |        0  |        1  | Row Total | \n",
      "------------------|-----------|-----------|-----------|\n",
      "                0 |     8238  |     2841  |    11079  | \n",
      "                  | 8232.374  | 2846.626  |           | \n",
      "                  |    0.004  |    0.011  |           | \n",
      "                  |   74.357% |   25.643% |   52.031% | \n",
      "                  |   52.067% |   51.928% |           | \n",
      "                  |   38.689% |   13.342% |           | \n",
      "                  |    0.062  |   -0.105  |           | \n",
      "------------------|-----------|-----------|-----------|\n",
      "                1 |     7584  |     2630  |    10214  | \n",
      "                  | 7589.626  | 2624.374  |           | \n",
      "                  |    0.004  |    0.012  |           | \n",
      "                  |   74.251% |   25.749% |   47.969% | \n",
      "                  |   47.933% |   48.072% |           | \n",
      "                  |   35.617% |   12.351% |           | \n",
      "                  |   -0.065  |    0.110  |           | \n",
      "------------------|-----------|-----------|-----------|\n",
      "     Column Total |    15822  |     5471  |    21293  | \n",
      "                  |   74.306% |   25.694% |           | \n",
      "------------------|-----------|-----------|-----------|\n",
      "\n",
      " \n",
      "Statistics for All Table Factors\n",
      "\n",
      "\n",
      "Pearson's Chi-squared test \n",
      "------------------------------------------------------------\n",
      "Chi^2 =  0.03119586     d.f. =  1     p =  0.8598041 \n",
      "\n",
      "Pearson's Chi-squared test with Yates' continuity correction \n",
      "------------------------------------------------------------\n",
      "Chi^2 =  0.02589738     d.f. =  1     p =  0.8721512 \n",
      "\n",
      " \n",
      "McNemar's Chi-squared test \n",
      "------------------------------------------------------------\n",
      "Chi^2 =  2157.894     d.f. =  1     p =  0 \n",
      "\n",
      "McNemar's Chi-squared test with continuity correction \n",
      "------------------------------------------------------------\n",
      "Chi^2 =  2156.985     d.f. =  1     p =  0 \n",
      "\n",
      " \n",
      "Fisher's Exact Test for Count Data\n",
      "------------------------------------------------------------\n",
      "Sample estimate odds ratio:  1.00556 \n",
      "\n",
      "Alternative hypothesis: true odds ratio is not equal to 1\n",
      "p =  0.8629243 \n",
      "95% confidence interval:  0.9450908 1.06987 \n",
      "\n",
      "Alternative hypothesis: true odds ratio is less than 1\n",
      "p =  0.5762927 \n",
      "95% confidence interval:  0 1.059359 \n",
      "\n",
      "Alternative hypothesis: true odds ratio is greater than 1\n",
      "p =  0.4360365 \n",
      "95% confidence interval:  0.9545028 Inf \n",
      "\n",
      "\n",
      " \n",
      "       Minimum expected frequency: 2624.374 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "CrossTable(bakerySales1$DayR, bakerySales1$CoffeeSales, fisher=TRUE, chisq = TRUE, mcnemar = TRUE, expected = TRUE, sresid=TRUE, format=\"SPSS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bebc1195-12e5-419d-94e0-f6c30831bfd0",
   "metadata": {},
   "source": [
    "## Check Assumption of Expected Frequencies\n",
    "\n",
    "In order to meet the assumption for the McNemar Chi-Square, you will need to have at least 5 expected per cell. With the lowest expected value being in the two thousands, you have definitely met this assumption!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e480bc8-5df8-4760-b0a5-60789896188c",
   "metadata": {},
   "source": [
    "## Interpret Results\n",
    "\n",
    "You will start by looking at the p value for McNemar's Chi-squared test. \n",
    "\n",
    "It doesn't usually matter whether you look at the original or the one with the continuity correction - they are usually pretty close. \n",
    "\n",
    "If the p value is less than .05, then this test is significant. This means that on this occasion, there is a difference in coffee sales from the beginning to the end of the month."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a10abd-7d43-4c8b-9b9b-09404bb2f64b",
   "metadata": {},
   "source": [
    "## Post Hocs\n",
    "\n",
    "What does that difference actually look like? \n",
    "\n",
    "Well that's a matter for post hocs, and again, like the independent Chi-Square, you will examine the standardized residuals. \n",
    "\n",
    "Anything with an absolute value of 2 (can be positive or negative) differs from expected. \n",
    "\n",
    "However, looking at your post hocs (which have been corrected to account for the possibility of Type I error), you find that none of your standardized residuals are over 2. \n",
    "\n",
    "This means that this test was not really significant after all. A good litmus test for this is to look at your row total percentages. \n",
    "\n",
    "See how sales at the beginning of the month are at 52%, and sales at the end of the month are 48%? \n",
    "\n",
    "Although these are technically different, they're pretty darn close, and the test has decided that they are similar enough that it is not significant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0dff56-f6da-4bc0-82a3-b2c9d4a48938",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
